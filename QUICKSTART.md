# 快速开始指南

## 前置要求

- Python 3.9 或更高版本
- 现代浏览器 (Chrome, Firefox, Edge等)
- 网络连接（用于安装依赖和加载CDN资源）

## Windows系统

### 1. 环境设置

双击运行或命令行执行：
```bash
scripts\setup.bat
```

这个脚本会：
- 检查Python环境
- 创建Python虚拟环境
- 安装所有必需的依赖包

### 2. 初始化数据库

首次运行需要初始化数据库和创建内置指标：
```bash
scripts\init_database.bat
```

### 3. 启动后端服务

打开一个新的命令行窗口，运行：
```bash
scripts\run_backend.bat
```

后端服务将在 `http://localhost:8000` 启动。
- API文档: http://localhost:8000/docs
- ReDoc文档: http://localhost:8000/redoc

### 4. 启动前端服务（可选）

如果要使用HTTP服务器，打开另一个命令行窗口：
```bash
scripts\run_frontend.bat
```

或者直接在浏览器中打开 `frontend/index.html` 文件。

前端地址：`http://localhost:8080` (如果使用HTTP服务器) 或直接打开本地文件。

## Linux/Mac系统

### 1. 环境设置

```bash
chmod +x scripts/setup.sh
./scripts/setup.sh
```

### 2. 初始化数据库

```bash
chmod +x scripts/init_database.sh
./scripts/init_database.sh
```

### 3. 启动后端服务

```bash
chmod +x scripts/run_backend.sh
./scripts/run_backend.sh
```

### 4. 启动前端服务

在浏览器中打开 `frontend/index.html` 或使用HTTP服务器：
```bash
cd frontend && python3 -m http.server 8080
```

## 核心概念说明

### 智能体API端点

**作用**：这是被评估的智能体系统的接口地址。系统会向这个API发送测试问题，获取智能体的响应，然后评估其性能。

**重要**：**不需要真实API也可以测试！** 系统提供了多种测试方式：

#### 方式1：系统内置模拟响应（最简单）

**使用方法**：在创建任务时，**直接留空API端点字段**

**工作原理**：
- 系统会自动使用内置的模拟响应
- 返回格式：`"模拟响应: {问题前50字符}..."`
- 无需启动任何额外服务，适合快速测试系统功能

**适用场景**：测试评估流程、查看界面、验证指标计算逻辑

#### 方式2：本地模拟API服务器（推荐用于完整测试）

**使用方法**：
1. 启动模拟API服务器：
   ```bash
   scripts\run_mock_api.bat
   ```
2. 在创建任务时，填写：
   - **API端点**: `http://localhost:9000/api/chat`
   - **API密钥**: 留空

**特点**：
- 提供更真实的API交互体验
- 根据问题关键词返回不同的模拟响应
- 模拟真实的HTTP请求/响应流程
- 可以测试API连接、错误处理等功能

**适用场景**：完整测试评估流程、验证API调用逻辑

#### 方式3：真实API（生产环境）

**示例**：
- OpenAI API: `https://api.openai.com/v1/chat/completions`
- 自定义API: `http://localhost:5000/api/chat`
- 其他LLM API: 根据提供商的文档配置

**工作原理**：
1. 系统从数据集中读取一个测试问题（`input`字段）
2. 将问题发送到智能体API端点
3. 接收智能体的响应文本
4. 将响应与标准答案进行比较，计算各项评估指标

### 数据集

**作用**：数据集包含用于测试智能体的所有问题和标准答案。每个测试样本包含：
- `input`: 输入给智能体的问题或提示
- `expected_output`: 期望的输出（用于计算准确率等指标）
- `reference`: 参考答案列表（用于计算BLEU、ROUGE等生成质量指标）

**支持的数据源类型**：
1. **JSON文件**：本地JSON文件，格式为数组，每个元素是一个测试样本
2. **CSV文件**：本地CSV文件，每行是一个测试样本
3. **API接口**：从远程API获取测试数据

**数据集路径示例**：
- **留空（推荐）**: 自动使用默认数据集 `app/data/samples.json`
- 相对路径: `app/data/samples.json`（相对于项目根目录）
- 绝对路径: `C:\Users\YourName\data\test_samples.json`

## 完整评估任务流程

### 第一阶段：准备阶段

1. **创建任务**
   - 填写任务名称和描述
   - 配置智能体API端点（或留空使用模拟响应）
   - 选择数据集类型和路径
   - 选择要评估的指标（如BLEU、ROUGE-L、准确率等）

### 第二阶段：执行阶段（自动）

系统后台执行以下步骤：

1. **加载数据集**
   ```
   系统读取数据集文件/API → 解析为测试样本列表
   ```

2. **遍历测试样本**
   对于数据集中的每个样本：
   ```
   a. 提取问题（input字段）
   b. 调用智能体API → 获取智能体响应
   c. 准备评估数据：
      - 智能体响应 vs 期望输出（expected_output）
      - 智能体响应 vs 参考答案（reference）
   d. 计算各项指标：
      - 准确率：比较响应与期望输出
      - BLEU分数：n-gram匹配度
      - ROUGE-L：最长公共子序列
      - 其他选中的指标
   e. 更新进度（每处理10个样本更新一次）
   ```

3. **聚合结果**
   ```
   所有样本的指标结果 → 计算平均值、最大值、最小值、标准差
   ```

4. **生成综合报告**
   ```
   各指标得分 → 加权总分 → 分析报告 → 可视化数据（雷达图）
   ```

### 第三阶段：查看结果

1. **任务完成后**，点击"查看详情"
2. **分析报告页面**显示：
   - **总体得分**：所有指标的加权综合得分（0-1之间）
   - **雷达图**：直观展示智能体在不同维度上的性能
   - **详细指标得分**：每个指标的具体得分和统计信息
   - **文本分析报告**：包含性能分析和改进建议

## 使用示例

### 创建评估任务

#### 方式A：快速测试（使用内置模拟响应）

1. 在浏览器中打开前端界面（`http://localhost:8080`）
2. 点击"创建新任务"按钮
3. 填写任务信息：
   - **任务名称**: 例如 "系统功能测试"
   - **智能体API端点**: **留空**（使用系统内置模拟响应）
   - **API密钥**: 留空
   - **数据集类型**: 选择 "JSON文件"
   - **数据集路径**: **留空**（将自动使用默认数据集 `app/data/samples.json`）或填写自定义路径
   - **选择评估指标**: 勾选需要的指标
4. 点击"创建任务"

**优点**：无需额外配置，立即测试

#### 方式B：完整测试（使用本地模拟API）

1. **先启动模拟API服务器**（新开一个命令行窗口）：
   ```bash
   scripts\run_mock_api.bat
   ```
   等待看到 "API端点: http://localhost:9000/api/chat" 的提示

2. 在前端界面创建任务：
   - **智能体API端点**: `http://localhost:9000/api/chat`
   - **API密钥**: 留空
   - 其他配置同方式A

**优点**：更真实的API交互，可以测试完整的调用流程

#### 方式C：使用真实API（生产环境）

1. 在前端界面创建任务：
   - **任务名称**: 例如 "ChatGPT问答能力评估"
   - **智能体API端点**: `https://api.openai.com/v1/chat/completions`
   - **API密钥**: 填入你的API密钥
   - 其他配置按要求填写

**注意**：使用真实API可能会产生费用，请谨慎使用

### 启动评估任务

1. 在任务列表中，找到刚创建的任务
2. 点击"启动任务"按钮
3. 任务状态将变为"执行中"
4. **实时监控**：
   - 进度条显示处理进度（如：3/5 样本已处理）
   - 可以刷新页面查看最新状态
5. 等待任务完成（根据数据集大小和API响应速度，可能需要几分钟）

### 查看评估结果

1. 任务完成后，状态变为"已完成"
2. 点击"查看详情"按钮
3. 系统自动跳转到"分析报告"页面
4. 查看评估结果：
   - **总体得分**: 例如 0.85（满分1.0）
   - **雷达图**: 直观显示各维度性能
   - **详细得分**: 
     - BLEU: 0.78
     - ROUGE-L: 0.82
     - 准确率: 0.90
   - **分析报告**: 包含性能分析和建议

## 示例数据集格式

系统内置了示例数据集 `backend/app/data/samples.json`，格式如下：

```json
[
    {
        "input": "什么是人工智能？",
        "expected_output": "人工智能是计算机科学的一个分支，旨在创建能够执行通常需要人类智能的任务的系统。",
        "reference": [
            "人工智能是计算机科学的一个分支，旨在创建能够执行通常需要人类智能的任务的系统。",
            "AI是让机器能够像人类一样思考和学习的领域。"
        ]
    },
    {
        "input": "编写一个Python函数来计算斐波那契数列",
        "expected_output": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)",
        "reference": [
            "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)"
        ]
    }
]
```

**字段说明**：
- `input`: 输入给智能体的问题
- `expected_output`: 期望的标准答案（用于准确率计算）
- `reference`: 参考答案列表（可以有多个，用于BLEU/ROUGE计算，更贴近真实场景）

### 创建自定义数据集

你可以创建自己的JSON数据集：

```json
[
    {
        "input": "你的问题1",
        "expected_output": "期望答案1",
        "reference": ["参考答案1", "参考答案2"]
    },
    {
        "input": "你的问题2",
        "expected_output": "期望答案2",
        "reference": ["参考答案"]
    }
]
```

保存为JSON文件，然后在创建任务时指定路径即可。

## 常见问题

### Q: 后端启动失败，提示端口被占用
A: 修改 `scripts/run_backend.bat` 中的端口号（默认8000）

### Q: 前端无法连接到后端
A: 检查：
1. 后端服务是否正在运行
2. 前端中的 `API_BASE_URL` 是否正确（默认 `http://localhost:8000`）
3. 浏览器控制台是否有CORS错误

### Q: 评估任务一直处于"执行中"状态
A: 检查：
1. 后端服务是否正常运行
2. 数据集路径是否正确
3. 查看后端日志输出

### Q: 指标计算出错
A: 确保数据集格式正确，特别是：
- BLEU和ROUGE指标需要 `reference` 字段（数组格式）
- 准确率等指标需要 `expected_output` 字段

## 下一步

- 查看 `README.md` 了解更多功能
- 访问 http://localhost:8000/docs 查看完整的API文档
- 自定义评估指标（在指标体系中）
- 集成你的智能体API

## 技术支持

如有问题，请查看：
- 后端日志输出
- 浏览器控制台（F12）
- API文档（http://localhost:8000/docs）

