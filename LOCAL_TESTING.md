# 本地测试指南

## 快速开始：无需真实API的测试方法

本系统提供了多种本地测试方式，**完全不需要配置真实的智能体API**。

## 测试方式对比

| 方式 | 难度 | 适用场景 | 需要启动的服务 |
|------|------|----------|----------------|
| **内置模拟响应** | ⭐ 最简单 | 快速测试系统功能 | 无需额外服务 |
| **本地模拟API** | ⭐⭐ 简单 | 完整测试API调用流程 | 模拟API服务器 |
| **真实API** | ⭐⭐⭐ 复杂 | 生产环境评估 | 无 |

## 方式1：内置模拟响应（推荐快速测试）

### 特点
- ✅ 无需任何额外配置
- ✅ 无需启动额外服务
- ✅ 立即可以测试
- ⚠️ 响应内容是固定的模拟文本

### 使用步骤

1. **直接创建任务**，在"智能体API端点"字段中**留空**
2. 其他配置正常填写即可
3. 启动任务，系统会自动使用模拟响应

### 模拟响应格式

系统会返回：
```
模拟响应: {问题前50字符}...
```

例如，如果问题是"什么是人工智能？"，响应会是：
```
模拟响应: 什么是人工智能？...
```

### 适用场景
- ✅ 测试评估流程是否正常
- ✅ 查看界面和功能
- ✅ 验证指标计算逻辑
- ✅ 测试数据集加载功能

## 方式2：本地模拟API服务器（推荐完整测试）

### 特点
- ✅ 更真实的API交互体验
- ✅ 可以测试API调用、错误处理等
- ✅ 根据问题关键词返回不同响应
- ⚠️ 需要启动一个额外的服务

### 使用步骤

#### 步骤1：启动模拟API服务器

打开新的命令行窗口，运行：
```bash
scripts\run_mock_api.bat
```

或者手动启动：
```bash
cd backend
venv\Scripts\activate
python mock_api.py
```

你会看到：
```
==================================================
启动模拟API服务器...
API端点: http://localhost:9000/api/chat
==================================================
```

**保持这个窗口打开**，模拟API服务会一直运行。

#### 步骤2：创建评估任务

在前端界面创建任务时：
- **智能体API端点**: `http://localhost:9000/api/chat`
- **API密钥**: 留空
- 其他配置正常填写

#### 步骤3：启动评估任务

正常启动任务，系统会调用本地的模拟API。

### 模拟API的响应逻辑

模拟API会根据问题中的关键词返回不同的响应：

- 包含"人工智能" → 返回AI相关的标准答案
- 包含"Python" → 返回Python相关的答案
- 包含"函数" → 返回函数相关的答案
- 其他 → 返回通用响应

### 停止模拟API

在运行模拟API的窗口按 `Ctrl+C` 停止服务。

## 方式3：使用真实API（生产环境）

### 配置真实API

如果你有真实的智能体API（如OpenAI、Claude等），可以这样配置：

#### OpenAI API示例

1. 获取API密钥：访问 https://platform.openai.com/api-keys
2. 创建任务时填写：
   - **API端点**: `https://api.openai.com/v1/chat/completions`
   - **API密钥**: 你的OpenAI API密钥

#### 自定义API示例

如果你的智能体API在本地运行（如 `http://localhost:5000/api/chat`）：

1. 确保你的智能体服务正在运行
2. 创建任务时填写：
   - **API端点**: `http://localhost:5000/api/chat`
   - **API密钥**: 如果需要认证，填入密钥；否则留空

### API接口要求

系统期望的API接口格式：

**请求格式**：
```json
POST /api/chat
Content-Type: application/json
Authorization: Bearer {api_key}  // 如果提供了API密钥

{
    "prompt": "用户的问题",
    "max_tokens": 500,
    "temperature": 0.7
}
```

**响应格式**（支持以下任一格式）：
```json
// 格式1：包含response字段
{
    "response": "智能体的回答"
}

// 格式2：包含text字段
{
    "text": "智能体的回答"
}

// 格式3：直接返回文本字符串
"智能体的回答"
```

如果你的API格式不同，需要修改 `backend/app/services/evaluation_service.py` 中的 `_call_agent` 方法来适配。

## 测试建议

### 第一次使用

1. **先用方式1（内置模拟）**：快速验证系统是否正常工作
2. **再用方式2（模拟API）**：测试完整的API调用流程
3. **最后用方式3（真实API）**：进行实际的智能体评估

### 测试数据集

建议使用内置的示例数据集 `backend/app/data/samples.json` 进行测试，包含5个测试样本。

### 测试指标

第一次测试时，建议选择：
- BLEU分数
- ROUGE-L分数
- 准确率

这些指标计算较快，适合快速验证。

## 常见问题

### Q: 模拟API无法启动？

A: 检查：
1. 虚拟环境是否正确创建
2. 依赖是否已安装（运行 `scripts\setup.bat`）
3. 端口9000是否被占用

### Q: 评估任务显示"API调用失败"？

A: 检查：
1. 模拟API服务是否正在运行（方式2）
2. API端点地址是否正确
3. 网络连接是否正常

### Q: 如何查看模拟API的请求日志？

A: 在运行模拟API的窗口中，可以看到所有接收到的请求。

### Q: 可以修改模拟API的响应吗？

A: 可以！编辑 `backend/app/mock_api.py` 文件中的 `RESPONSE_TEMPLATES` 字典，添加你想要的响应模板。

## 总结

- **最快测试**：API端点留空，使用内置模拟
- **完整测试**：启动 `scripts\run_mock_api.bat`，使用本地模拟API
- **真实评估**：配置真实的智能体API端点

所有方式都可以完成评估任务，选择最适合你当前需求的即可！

